# SherLogDB

<img src="logo.svg" alt="logo" width="300"/>

### Опис
SherlogDB - високопродуктивна колонкова СУБД для логів, що надає, паралельну обробку, гарантії ACID, SQL-подібну мову запитів, видалення логів за TTL, індексацію, автосортування за часом, та інше.

### Фічі
- **Гарантії ACID**, за рахунок версіонування змін та системи бекапа даних;
- **Паралельна обробка** запитів на читання, запис, видалення логів і сховищ;
- **SQL-like мова запитів** з можливістю фільтрації записів за умовою, сортування, групування, фільтрації груп, агрегації та інше;
- Система здатна записувати до **400 000 логів за секунду** (~3 КБ кожен, тобто ~1.2 ГБ/с) при 200 паралельно запущених письменниках, кожен із яких записує по 2 000 логів, на типовому SSD зі швидкістю запису ~600 МБ/с.
- Швидке одержання логів у потрібному часовому діапазоні за рахунок **індексування**;
- Пошук по **конкретним колонкам**, не торкаючись інших;
- Планова **структуризація та сортування** логів;
- Збирач сміття: планові видалення файлів, що не використовуються (**без порушення узгодженості**);
- Видалення старих логів за **TTL**;
- Є можливість обмеження ресурсів та управління їх розподілом через налаштування пулу воркерів.

(*Детальніше про фічі і не тільки можна дізнатися в документації [Docs_ua.md](Docs_ua.md)*)

### Технології

Golang v1.23.1

Libs:
- github.com/google/**uuid** - v1.6.0
- github.com/j-hitgate/**sherlog** - v1.0.0
- github.com/joho/**godotenv** - v1.5.1
- github.com/labstack/**echo**/v4 - v4.13.3
- github.com/stretchr/**testify** - v1.10.0
- github.com/vmihailenco/**msgpack**/v5 - v5.4.1

### Збірка та запуск
Команда для будування та запуску виконавчого файлу:
```bash
go build -o sherlogdb
./sherlogdb
```

Конфігурація `.env`:
- `PORT` - порт, на якому буде запущено СУБД (за замовчуванням `8070`);
- `WRITERS` - кількість запущених письменників (за замовчуванням `10`);
- `READERS` - кількість запущених читачів (за замовчуванням `10`);
- `DELETERS` - кількість запущених удаляторів (за замовчуванням `1`);
- `PASSWORD` - пароль адмін-доступу до СУБД;
- `DB_LOG_LEVEL` - рівень логування СУБД (за умовчанням `0`);
- `DB_LOGS_DIR` - папка для зберігання логів СУБД (якщо не вказати, то логи не будуть записуватися на диск);
- `LOGS_TTL` - час життя логів (за замовчуванням 30 днів);
- `ALIGNING_CHUNKS_PERIOD` - частота вирівнювання чанків (за замовчуванням кожну 1 хвилину);
- `DELETING_EXPIRED_CHUNKS_PERIOD` - частота перевірки наявності та видалення застарілих логів (за замовчуванням кожну 1 годину);
- `REMOVING_FILES_PERIOD` - частота видалення файлів, що не використовуються (за замовчуванням кожну 1 хвилину);

Щоб завершити роботу БД, окрім "витягування вилки з розетки", можна використовувати м'яке завершення роботи відправивши наступний запит (пароль вказаний у конфігурації за ключом `PASSWORD`):
```bash
curl -X POST http://127.0.0.1:8070/shutdown \
    -H 'Content-Type: application/json'
    -d '{"password": "your_password"}'
```

### APIs
**Логи:**
- **POST /logs** - додавання логів
- **POST /logs/search** - пошук та отримання логів
- **DELETE /logs** - видалення логів

**Сховища:**
- **GET /storages** - отримання списку сховищ
- **POST/storage** - створення сховища
- **DELETE /storage** - видалення сховища

**Адмін-панель:**
- **POST /shutdown** - завершення роботи СУБД

(*Докладніше про API у файлі [APIs.md](APIs.md)*)

### Навантажувальне тестування
Команда запуску теста через [k6](https://k6.io/open-source): `k6 run vus_test.js`

У тесті відбуваються симуляція запитів на додавання (**POST /logs**) та пошук (**POST /logs/search**) логів від багатьох користувачів. Логи, згенеровані в ході тесту, зберігатимуться по шляху "*storages/storage/*", який потрібно **попередньо створити**.

Конфігурація тесту в скрипті `vus_test.js`:
```js
const config = {
    randLogs      // генерувати рандомні логи (true) або використовувати заготовлені (false) 
    minLogsToSend // Мінімальна кількість логів, яке надсилає віртуальний користувач 
    maxLogsToSend // максимальна кількість логів, яке відправляє віртуальний користувач 
    writersRatio  // співвідношення письменників та читачів
}
export let options = {
    vus      // кількість віртуальних користувачів 
    duration // тривалість тестування
}
```

### Приклади
Припустимо, що нам потрібно зберігати логи про дії користувачів. Створимо для цих логів сховище `users` (аналог таблиці в SQL):
```bash
curl -X POST http://127.0.0.1:8070/storage \
    -H 'Content-Type: application/json'
    -d '{"storage": "users"}'
```

Тепер до цього сховища можна додавати логи. Додамо пару:
```bash
curl -X POST http://127.0.0.1:8070/logs \
    -H 'Content-Type: application/json'
    -d '{"storage": "users", "logs": [
        {
            "timestamp": 1748354137,
            "level":     4,
            "traces":    ["req_1f5a4ff6e8"],
            "entity":    "customer",
            "entity_id": "26",
            "message":   "Ordered products",
            "modules":   ["_OrderMicroservice3", "orderAPI"],
            "labels":    ["VIP", "regular"],
            "fields":    {"Product": "Pen", "Price": "8.00", "Number": "5"}
        },
        {
            "timestamp": 1748423691,
            "level":     4,
            "traces":    ["req_6a53f4e387"],
            "entity":    "admin",
            "entity_id": "7",
            "message":   "Changed price of product",
            "modules":   ["_PanelMicroservice2", "changePriceAPI"],
            "fields":    {"Product": "Pen", "NewPrice": "10.00"}
        }
    ]}'
```

Якщо ми захочемо дізнатися які помилки введення здійснили **покупці (крім постояльців)** і **адміни** за останні 30 днів, а також підрахувати скільки таких помилок припадає на адмінів, тобто знайти повідомлення логів з рівнем 3 (`level == 3`), пов'язані з **покупцями (`entity == "customer"`), в мітки яких не входить "regular" (`!("regular" => labels")`)** та **адмінами (`entity == "admin"`)**, то можна ввести даний запит:
```bash
curl -X POST http://127.0.0.1:8070/logs/search \
    -H 'Content-Type: application/json'
    -d '{
        "storage":       "users",
        "select":        ["timestamp", "entity", "message", "count[entity == ?0]"],
        "aggreg_values": ["admin"],
        "time_range":    "last 30d",
        "where":         "level == ?0 & ((entity == ?1 & !(?2 => labels)) | entity == ?3)",
        "where_values":  [3, "customer", "regular", "admin"]
    }'
```

В результаті ми отримаємо список з 4-ма колонками, вказаними в `select`, наприклад:
```json
[
    [1777112345, "customer", "Incorrect password", 2],
    [1777212345, "customer", "Incorrect email",    2],
    [1777312345, "admin",    "Product not exists", 2],
    [1777412345, "admin",    "Invalid new price",  2],
    [1777512345, "customer", "Incorrect password", 2]
]
```
Обратите внимание, что в данном запросе мы затрагиваем только те логи, которые находятся примерно в указанном временно диапазоне (30 дней) и значения лишь тех колонок, которые используются в запросе (`message`, `level`, `entity`, `labels`) и `timestamp`, который подгружается в любом случае. То есть СУБД не сканирует всю базу данных и все колонки, а лишь то что нужно для выполнения запроса. Также значения используемые в условиях передаются отдельно в `aggreg_values` и `where_values`, чтобы избежать SQL-Injection. Полученные результаты по умолчанию отсортированы по дате и времени (то есть по `timestamp`), так как логи уже хранятся в отсортированном виде.

Зверніть увагу, що в даному запиті ми торкаємося тільки тих логів, які знаходяться приблизно в зазначеному часовому діапазоні (30 днів) і значення лише тих колонок, які використовуються в запиті (`message`, `level`, `entity`, `labels`) і `timestamp`, яка завантажується в будь-якому випадку. Тобто СУБД не сканує всю базу даних і всі колонки, а лише те, що потрібно для виконання запиту. Також значення, які використовувалися в умовах передаються окремо в `aggreg_values` і `where_values`, щоб уникнути SQL-Injection. Отримані результати за умовчанням відсортовані за датою і часом (тобто за `timestamp`), оскільки логи вже зберігаються у відсортованому вигляді.