# Документація

### Старт та запуск
При створенні `Service` (`New()`) відбувається реєстрація хендлерів API, а під час його запуску (`Run()`):
1. Виконуються транзакції з папки "*transactions/*", які не встигли виконуватися з попереднього запуску (там же знаходяться бекапи файлів);
2. З "*storages/*" читаються сховища та метаінформація чанків, при цьому:
    - старі версії чанків видаляються, залишаючи лише їх останні версії;
    - позначені як віддалені сховища (ті які мають у собі файл "*\_deleted\_*") і чанки теж видаляються;
3. Запуск письменників, читачів, удаляторів логів та планувальника;
4. Запуск сервера.

### Папки
- **Сховища** - це папки, розташовані в директорії "*storages/*". Якщо сховище видаляють, спочатку воно позначається як видалене, тобто відбувається додавання порожнього файлу "*\_deleted\_*" в папку сховища, а потім може бути фізичне видалення;
- **Чанки** - це папки, розташовані у сховищах. 
    - В імені міститься ID та версія чанка розділені символом '_'. Наприклад, чанк з ID 5 та версією 11 буде називатися "*5_11/*";
    - Усередині себе чанк має файли колонок та файл з метаінформацією ("*meta*");
    - Чанк може бути "сирим", якщо в нього ще пишуть і в метаінформації вказані офсети для його колонок;
    - Читачі сирих чанків читають лише доступну кількість значень із файлів-колонок, а письменники можуть додавати нові значення поверх доступних. Таким чином, при паралельній роботі один другому не заважає;
    - Не сирі чанки є відсортованими за колонкою `timestamp`.
- **Транзакції** - це файли з інструкціями/командами, які містяться в папці "*transactions/*". Транзакції ідемпотентні, тому їхнє повторне виконання не призведе до збоїв. Можуть бути такі команди:
    - **Cut** - обрізати файл за вказаною довжиною;
    - **Remove** - видалення папки/файлу;
    - **Rename** - перейменування папки/файлу.
- **Завдання видалення** - це файли із запитами на видалення від користувача (модель `DeleteQuery`), розташовані у папці "*delete_tasks/*". Завдання видаляються лише після того, як вони були виконані.

### Константи
Константи, які знаходяться в файлі "*models/consts.go*":
- `BLOCK_MAX_SIZE` - максимальна кількість чанків в блоці `MetasMap` (рекомендується `100`);
- `MAX_LOGS_IN_CHUNK` - максимальна кількість логів в чанці (рекомендується `2000`);
- `DIR_STORAGES` - папка зі сховищами;
- `DIR_TRANSACTIONS` - папка для транзакцій;
- `DIR_DELETE_TASKS` - папка для задач видалення логів від користувача;
- `C_*` (column) - всі константи із даним префіксом являються іменами колонок логів;
- `AG_*` (aggregator) - всі константи із даним префіксом являються іменами агрегаторів.

### Карта метаінформації та версіонування
`MetasMap` - це агент, що зберігає в собі стан БД та його версію, тобто інформацію про сховища та їх чанки. Є **єдиним джерелом істини** та контролером версій.

Приклад структури зберігання:
```
- storage 1:
    - Chunk 1 meta
    - Chunk 2 meta
- storage 2:
    - Chunk 1 meta
```

- При кожному оновленні стану агента його версія збільшується на одиницю, тобто **кожен стан має свою версію**.
- Доступ до агента **ексклюзивний (у кожний момент часу лише одна горутина має доступ)**, але він може повернути снепшот стану (**доступний тільки для читання**) для подальшої вже паралельної роботи з ним. При цьому потрібно мати на увазі, що це лише снепшот конкретної версії, і не є релевантним станом (немає гарантій, що це остання версія стану).
- А для того, щоб заблокувати стан від подальших змін, можна:
    - спочатку отримати необхідні чанки з нинішньої версії;
    - поставити лок на отримані чанки;
    - потім отримати ці чанки знову, з впевненістю що цей снепшот буде релевантним станом, так як ніхто більше не може змінювати залочені чанки, крім того хто поставив лок;
    - після зміни даних, важливо **спочатку оновити стан, і тільки після зняти локи** (необхідні операції можна помістити в callback функцію задачі `UpdateStateTask`, яка виконується після оновлення стану), так як якщо спочатку зняти лок, є ймовірність, що чанк залочить хтось інший і отримає не релевантний стан БД:
    ```js
    - Goroutine A: Chunk version 5 changes started...
    - Goroutine A: Unlocked chunk version 5   // спочатку зняв лок
    - Goroutine B: Got chunk version 5
    - Goroutine B: Locked chunk version 5
    - Goroutine A: Updated chunk to version 6 // потім оновив версію, але горутина В уже спіймала чанк версії 5
    - Goroutine B: Chunk version 5 changes started...
    - Goroutine B: Chunk change error, 5 is not latest version! // помилка
    ```
- Є можливість зарезервувати версію стану методом `ReserveVersion()` на випадок, якщо чанки/сховища відзначать як видалені і збирач сміття спробує фізично видалити їх, поки їх ще читають. Простіше кажучи сказати "не видаляй те, з чим я ще працюю". Метод `ReserveVersion()` повертає callback функцію для розрезервації.
- Якщо в новому стані відсутні чанки або сховища (тобто їх віртуально видалили), то їх файли додаються в чергу для фізичного видалення (які потім підхоплює збирач сміття), і якщо жодна з версій, на яких ці чанки/сховища ще існують, не використовуються (версія не ким не зарезервована), то вони фізично видяляються.
- Оновлення стану можна виконати асинхронно, викликав метод `Update()` та передав йому задачу з інструкциями для оновлення стану (модель `UpdateStateTask`). Ці задачі виконує всього одна горутина, щоб забезпечити послідовність змін. Так як під час оновлення стану потрібно робити його дублікат, аби запобігти конфліктів, то метаінформація (моделі `Meta`) була поділена на блоки, і у випадку оновлення, дублюються не весь список, а лише ті блоки, які були затронуті. Але якщо кількість віртуально видалених мета перевищіть деяке значення, то відбудеться перескладання всього списку метаінформації, щоб позбутися "дірок".

### Аналізатор умов
Візьмемо за приклад таку умову: `level >= ?0 & (entity == ?1 & ?2 => labels) | !(level == ?3)`

1. Спочатку умова розбивається на пари блоків поділені логічними операторами AND (`&`) та OR (`|`), де другий блок завжди проста умова, а перший це сукупність попередніх, наприклад, в умові `A & B | C` першою парою буде `A & B` (назвемо це умовою `D`), а другою парою буде `D | C`. При чому спочатку до уваги беруться умови, що в дужках, а потім зовнішні. Тобто умову вище можна подати у вигляді дерева:
```
       entity == ?1     ?2 => labels
             \               /
              \____[ & ]____/
                    /
level >= ?0        /
      \           /
       \__[ & ]__/
             \        !(level == ?3)
              \             /
               \___[ | ]___/
```
(*Далі листя дерева це **прості умови**, а об'єднані це **складні умови***)

Якщо потрібно інвертувати умову, її потрібно обернути в дужки і на початку поставити символ `!`, тобто блок `!(level == 4)` буде істинним, якщо `level` буде будь-яким числом крім 4.

Пари умов із їхнім логічним оператором зберігаються в агенті `Comparator`.

2. Далі відбувається аналіз простих умов. Спочатку парсинг оператора (`==`, `!=` - порівняння, `>`, `<`, `>=`, `<=` - більше менше, `=>` - входження в масив) та двох операндів. Операндами можуть бути: 
    - Конкретні значення, тобто `?i`, де `i` це індекс масиву зі значеннями, які можна отримати з масивів `where_values`, `having_values` або `aggreg_values`; 
    - Колонка лога (`level`, `entity`, `labels` та інші), значення якої буде підставлятися замість назви колонки; 
    - Агрегації (`avg`, `count`, `max` та інші), замість яких буде використовуватися результати цих агрегацій.

При цьому в умові `where` операндами не можуть бути агрегації, тому що вона призначене для фільтрування записів з БД, а не для груп. А в умові `having` навпаки, операндами не можуть бути колонки логів, окрім групуючої, оскільки ця умова призначена для фільтрації груп.

Також враховуються типи оперантів в умові: 
- Для операторів `==``!=` важливо щоб обидва операнди були одного типу; 
- Для операторів `>`, `<`, `>=`, `<=` важливо щоб обидва операнда були числами; 
- Для оператора `=>` важливо, щоб другий операнд був масивом, елементи якого одного і того ж типу з першим операндом.

Типи агрегацій та колонок можна переглянути у файлі [models/consts.go](models/consts.go).

### Агрегатори
Агрегатори – це агенти, які агрегують значення логів. Агрегатори в умовах представлені як функції з параметрами (`aggr_name[arg1, arg2...]`). У СУБД є такі агрегатори: 
- `avg[column, condition]` - обчислює середнє значення колонки `column`, які виходять в умову `condition`; 
- `count[condition]` - рахує кількість записів, які виходять в умову `condition`; 
- `max[column, condition]` та `min[column, condition]` - знаходить максимальне та мінімальне значення колонки `column`, які виходять в умову `condition`; 
- `sum[column, condition]` - рахує суму значень колонки `column`, які виходять в умову `condition`.

(*Параметр `condition` є опціональним у всіх агрегаціях, якщо його не передати, то агрегація застосовується до всіх записів*)

### Письменник
`Writer` - це агент, призначений для запису логів по чанках у вказане сховище. Щоб запустити воркера-письменника для передачі йому логів на запис по каналу, потрібно викликати метод `RunWriter()`.

При створенні агента, автоматично запускаються горутини для запису в колонки (`columnWriter`), щоб писати одночасно у всі колонки.
Кожен `columnWriter` робить наступне:
- дістає значення з лога по присвоєній йому колонці;
- конвертує значення в байти використовуючи пакет `msgpack`;
- Отримує довжину сконвертованого масиву байт і переводить її в масив з 2-х байт (тобто довжина еквівалентна типу `uint16`);
- після чого додає ці 2 масиви (із закодованими довжиною та значенням) у слайс із байтових масивів для запису у файл.

Приклад:
```go
ptrToValue, _ := log.Get("some_column")
data, _ := msgpack.Marshal(ptrToValue)
lenBytes := lenToByteArray(len(data))
bytesArrayForWrite = append(bytesArrayForWrite, lenBytes, data)

// Приклад того що буде в файлі-колонці (x - деякий байт):
// 0 3 x x x 0 2 x x 0 4 x x x x
```
Таким чином за першими двома байтами можна дізнатися скільки займає послідуюче закодоване значення і прочитати рівно стільки ж байт для декодування, а потім перейти до наступного значення.

Якщо кількість логів, яку потрібно записати, вміщується в чанк, то вони просто добавляються. Наприклад, коли максимальний розмір чанка 2000 логів і у чанці вже лежить 1000, то можна легко записати ще 100 логів.

А коли кількість логів перевищує максимальний обсяг чанка, то проводиться наступний алгоритм:
- Читаємо існуючі логи з чанку;
- Обчислюємо скільки нових логів ще можна дописати в даний чанк щоб досягти максимального обсягу та отримуємо цей зріз логів;
- Склеюємо прочитані та зріз нових логи в один масив та сортуємо його;
- Записуємо відсортовані логи у нову версію даного чанка;
- Переходимо до наступного чанку.

Перед записом, чанки ставляться на бекап, для відкату змін у разі збою під час запису, і лише після успішного запису логів цей бекап скасовується, як підтвердження зміни. Після чого відбувається оновлення стану в `MetasMap`.

Щоб вирахувати наступний ID чанку, в який письменнику потрібно писати, він прибавляє до даного ID загальну кількість письменників. Наприклад, якщо буде запущено 3 письменника, які пишуть в чанки із ID 1,2, 3, то їх наступні ID чанків для запису будуть 4, 5, 6, і так далі. Таким чином письменники можуть працювати в одночас і не заважати один одному.

### Читач
`Reader` - це агент, призначений для читання логів із чанків вказаного сховища. Щоб запустити воркера-читача для передачі йому завдань читання логів по каналу, потрібно викликати метод `RunReader()`.

При створенні агента, автоматично запускаються горутини для читання колонок (`columnReader`), щоб читати одночасно всі колонки.
Кожен `columnReader` читає файл з колонкою, а потім у циклі бере перші 2 байти щоб обчислити довжину закодованого значення, потім бере зріз байт обчисленої довжини, щоб декодувати значення через пакет `msgpack`, і покласти його в поле лога. Кількість прочитаних значень дорівнює кількості доступних для читання логів (яка вказана в метаінформації чанка), тобто якщо в чанці реально знаходиться 6 повних логів і 1 недописаний (пошкоджений), але нам доступно лише 5 логів для читання, то прочитаємо ми тільки ці 5 логів/значень, не торкаючись інших даних.

### Удалятор
`Deleter` - це агент, призначений для **віртуального видалення** логів та чанків із вказаного сховища. Щоб запустити воркер-удалятор для передачі йому запитів видалення логів по каналу, потрібно викликати метод `RunDeleter()`.

Коли користувач робить запит на видалення логів, то створюється завдання, яке буде поступово виконуватися, тобто **видалення логів не відбувається відразу, але воно точно відбудеться**.

Видалення логів відбувається двома способами:
- **За часовим діапазоном.** Якщо у запиті видалення вказано лише часовий діапазон, то видалення відбувається тільки по ньому, тобто: 
    - Видалення частини логів з чанків, якщо вони потрапляють у діапазон; 
    - Видалення всього чанка, якщо всі його логи потрапляють у діапазон.
- **За умовою.** Якщо передана умова та часовий діапазон (опціонально), то відбувається видалення за умовою, тобто читання чанків та фільтрація їх логів, що потрапляють у діапазон (якщо діапазон не переданий, то фільтруються всі логи), після чого: 
    - Якщо логи не були видалені, то нічого не відбувається; 
    - Якщо лише деякі логи були видалені, то створюється нова версія чанку без видалених логів; 
    - Якщо всі логи було видалено, то видаляється весь чанк.

### Планувальник
`Scheduler` - це агент, призначений для запуску фонових воркерів, що виконують планові операції: 
- `Aligner` - отримує з `MetasMap` не "сирі" чанки з пересіченими часовими діапазонами, робить їх "вирівнювання" (тобто перезбирає їх), і записує нові версії чанків на диск. Часовий діапазон чанка, це `timestamp` найновішого та найстарішого лога в ньому. Наприклад якщо є 3 чанки `[1 5 6], [2 3 7], [4 8 9]`, то їх "вирівняна" версія виглядає так: `[1 2 3], [4 5 6], [7 8 9]`;
- `ExpiredDeleter` - отримує з `MetasMap` чанки, всі логи яких застаріли, і **віртуально** їх видаляє;
- `Remover` - отримує файли з `MetasMap` для **фізичного видалення**.
Для запуску даних воркерів, потрібно викликати методи `RunAligner()`, `RunExpiredDeleter()` та `RunRemover()` відповідно.

### Обробник логів
`LogProcessor` - це агент, який обробляє передані йому логи (фільтрує, групує, агрегує та інше) за вказаним запитом (модель `SearchQuery`), видаючи на виході результат у вигляді матриці значень із рядків і колонок.

1. Спочатку агенту передається запит користувача для:
    - Аналізу умов;
    - Аналізу агегацій;
    - Парсингу часового діапазону для пошуку логів;
    - Виявлення даних для завантаження (модель `LogLoadData`);
    - Валідації запиту в цілому.
2. Після аналізу запита, агенту можна передавати логи через метод `PutLogs()`, або через `PutLogsFromChanel()`, якщо є канал, з якого приходять логи. Під час передачі логів відбувається:
    - Фільтрація логів за умовою `where`;
    - Групування логів по колонці `group_by` (якщо вона була вказана в запиті);
    - Прохід логів через агрегатори.
3. Потім можна зібрати результати викликавши метод `GetResult()`, в якому відбувається:
    - Для логів:
        - Склеювання та сортування логів по колонці `order_by`;
        - Зріз логів по `offset` і `limit`;
        - Генерація результатів відповідно до того що вказано в `select`.
    - Для груп:
        - Отримання результатів агрегаторів кожної групи;
        - Сортування груп по `order_by`;
        - Зріз груп по `offset` і `limit`;
        - Генерація результатів відповідно до того що вказано в `select`.